{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SIR model\n",
    "A very basic model for the spread of a dissease is the Succeptible, Infected, Recovered (SIR) model. This model splits a population into three groups.\n",
    "\n",
    "1. $S(t)$ - the part of the population that is succeptible but not yet infected with the disease\n",
    "2. $I(t)$ - the part of the population that is infected with the disease\n",
    "3. $R(t)$ - the part of the population that has recovered from the disease. \n",
    "\n",
    "The SIR model uses a system of ODE's to describe how these three groups change over time. In it's most simple form, the model uses only the contact ration $\\beta$ and the mean recovery rate $\\gamma$ for this.\n",
    "\n",
    "Below is a python implementation of this simple model, taken from https://scipython.com/book/chapter-8-scipy/additional-examples/the-sir-epidemic-model/. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "# The SIR model differential equations.\n",
    "def deriv(y, t, N, beta, gamma):\n",
    "    S, I, R = y\n",
    "    dSdt = -beta * S * I / N\n",
    "    dIdt = beta * S * I / N - gamma * I\n",
    "    dRdt = gamma * I\n",
    "    return dSdt, dIdt, dRdt\n",
    "\n",
    "def SIR_model(beta=0.2, gamma=0.1, I0=1, R0=0, \n",
    "              N=1000, t=np.linspace(0, 160, 160)):\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    beta : float\n",
    "           contact rate\n",
    "    gamma : float\n",
    "            recovery rate\n",
    "    I0 : int\n",
    "         initial value infected\n",
    "    R0 : int\n",
    "         initial value recovered\n",
    "    N : int\n",
    "        population size\n",
    "    t : ndarray\n",
    "        points in time\n",
    "    \n",
    "    '''\n",
    "    S0 = N - I0 - R0\n",
    "    \n",
    "    # Initial conditions vector\n",
    "    y0 = S0, I0, R0\n",
    "    # Integrate the SIR equations over the time grid, t.\n",
    "    ret = odeint(deriv, y0, t, args=(N, beta, gamma))\n",
    "    S, I, R = ret.T\n",
    "    \n",
    "    return {'S':S, 'I':I, 'R':R}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Connecting the SIR model with the workbench\n",
    "\n",
    "Let's connect this simple model to the workbench. We make the following assumptions\n",
    "1. $\\beta$ and $\\gamma$ are uncertain. We assume that $\\beta$ is somewhere between 0.05 and 0.3, while $\\gamma$ is somewhere between 0.01, and 0.15.\n",
    "2. The outcomes of interest are $S(t)$, $I(t)$, and $R(t)$ over time.\n",
    "\n",
    "To connect the model to the workbench, we need to do at least 3 things:\n",
    "1. **Instantiate a model class**; the workbench comes with a variety of model classes for making it easy to connect with existing simulation packages such as Vensim, PySD, Simio, or Netlogo. Since we have a model implemented in Python, we can use the most basic Model class.\n",
    "2. **Specify the uncertain parameters** (and/or decision levers); Note below how the name of the parameters matched the name of the keyword arguments of the SIR_model function. The workbench makes a distinction between RealParameters, IntegerParameters, BinaryParameters, and CategoricalParameters. For this example, our parameters $\\beta$ and $\\gamma$ have a continuous range so we use RealParameters \n",
    "3. **Specify the outcomes of interest**; the workbench makes a distinction between TimeSeriesOutcomes and ScalarOutcomes. $S$, $I$, and $R$ are time series, so we use TimeSeriesOutcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ema_workbench import Model, RealParameter, TimeSeriesOutcome\n",
    "\n",
    "model = Model('SIR', function=SIR_model)\n",
    "\n",
    "model.uncertainties = [RealParameter('beta', 0.05, 0.3),\n",
    "                       RealParameter('gamma', 0.01, 0.15)]\n",
    "\n",
    "model.outcomes = [TimeSeriesOutcome('S'),\n",
    "                  TimeSeriesOutcome('I'),\n",
    "                  TimeSeriesOutcome('R')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The code above is a minimum working example of how to connect a model, the SIR_model function in this case, to the ema workbech. Even very large and complex cases will mimic this structure. \n",
    "\n",
    "# Running the model with the workbench\n",
    "\n",
    "The next step is to run the model. For this we use an evaluator and the perform_experiments method. The workbench by default will use a latin hypercupe sampler to generate points in the parameter space defined by the uncertainties and/or levers. The uncertainties jointly span the uncertainty space. The levers (not used in this example) span the lever space. A point in uncertainty space is a scenario. A point in lever space is a policy. The combination of a scenario and a policy (where either might be None) is an experiment. \n",
    "\n",
    "A few remarks on this\n",
    "1. The workbench assumes uniform distributions. During the class it will be explained in more detail why we make this assumption and what consequences follow from this.\n",
    "2. The workbench comes with a wide range of alternative samplers, some of which we will use later in the course\n",
    "3. The workbench offers support for taking advantage of the fact that many modern computers have multiple cores. See assingment 2 for this week for more on this. For now, we use a SequentialEvaluator\n",
    "4. The workbench treats sampling in the uncertainty space and the lever space separately. It will always execute a full factorial over the combination of the lever space and the uncertainty space.\n",
    "\n",
    "Let's run the model for 100 scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:01<00:00, 793.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from ema_workbench import SequentialEvaluator\n",
    "\n",
    "with SequentialEvaluator(model) as evaluator:\n",
    "    experiments, outcomes = evaluator.perform_experiments(scenarios=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/1000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from ema_workbench import MultiprocessingEvaluator\n",
    "\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    _ = evaluator.perform_experiments(scenarios=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ema_workbench import MultiprocessingEvaluator\n",
    "\n",
    "with MultiprocessingEvaluator(model, n_processes=7) as evaluator:\n",
    "    _ = evaluator.perform_experiments(scenarios=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualizing the results\n",
    "\n",
    "Now that we have run the model 100 times, we can visualize the results. The workbench comes with a range of analysis functions including some convenience functions for visualizing time series data. For now, we use the function `ema_workbench.analysis.plotting.lines`. If you want to get a sense of what other analyses are available, please read the online documentation at https://emaworkbench.readthedocs.io. Over the coming weeks, we will systematically go through many of the analyses that are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ema_workbench.analysis import plotting, plotting_util\n",
    "\n",
    "for outcome in outcomes.keys():\n",
    "    plotting.lines(experiments, outcomes, outcomes_to_show=outcome, \n",
    "                   density=plotting_util.Density.HIST)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A key element in exploratory modeling is to try to understand how points in the uncertainty space map to outcomes or types of outcomes. Since in this example, we only have 2 uncertain parameters, basic visual inspection can already give a fair bit of insight. Let's try to answer the following question: how do $\\gamma$ and $\\beta$ affect the severity and timing of the outbreak? To answer this we need to do the following:\n",
    "1. get the maximum value over time for $I$ for each scenario (use np.max)\n",
    "2. Establish the point in time of this maximum (use np.argmax)\n",
    "3. visualize how 1 and 2 are affected by $\\beta$ and $\\gamma$ **jointly** (use scatter plots with max I, and the point in time as color)\n",
    "4. How are timing and the maximum related to each other?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "I = outcomes['I']\n",
    "maxI = np.max(I, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "sc = ax.scatter(experiments.beta, experiments.gamma, c=maxI)\n",
    "plt.colorbar(sc)\n",
    "ax.set_xlabel('beta')\n",
    "ax.set_ylabel('gamma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "I = outcomes['I']\n",
    "timing = np.argmax(I, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "sc = ax.scatter(experiments.beta, experiments.gamma, c=timing)\n",
    "plt.colorbar(sc)\n",
    "ax.set_xlabel('beta')\n",
    "ax.set_ylabel('gamma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "sc = ax.scatter(maxI, timing)\n",
    "ax.set_xlabel('max. I')\n",
    "ax.set_ylabel('point in time')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}